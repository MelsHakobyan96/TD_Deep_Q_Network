# TD_Deep_Q_Network

 Deep Q Network using TD learning and experience replay, code is based on famous code from openai website, but I hoped the class architecture would be more flexible than my previous class, but I was wrong. 
 Experience replay helped in learning for lunar-lander but I want to implement Monte-Carlo technique with experience replay as well, hopefuly it will help in reducing learning variance and it will converge much faster, also thinking about implementing Dualing DQN, and Double DQN later.
